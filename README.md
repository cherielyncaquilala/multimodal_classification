# multimodal_classification

A multimodal approach using DenseNet and LSTM deep learning models was implemented to classify participant records into four health classes (neg_no_illness, neg_with_illness, pos_mod, pos_asymp_mild) based on the participant metadata (demographic and health information) and audio data (breathing and coughing sound) from the Coswara dataset (https://github.com/iiscleap/Coswara-Data).

